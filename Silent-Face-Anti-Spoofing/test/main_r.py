# import time
# import cv2
# import numpy as np
# import faiss
# import pickle
# import os
# import warnings
# import requests
# import threading
# from datetime import datetime
# from insightface.app import FaceAnalysis
# from src.anti_spoof_predict import AntiSpoofPredict
# from src.generate_patches import CropImage
# from src.utility import parse_model_name

# warnings.filterwarnings('ignore')

# # ====== C·∫•u h√¨nh ======
# MODEL_DIR = "./resources/anti_spoof_models"
# MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# DEVICE_ID = 0
# FAISS_PATH = "faiss_index/face_index.faiss"
# IDS_PATH = "faiss_index/student_ids.pkl"
# FAISS_THRESHOLD = 1.2
# API_URL = "http://localhost:5000/api/v1/exam-attendance/"

# # ====== Kh·ªüi t·∫°o m√¥ h√¨nh ch·ªëng gi·∫£ m·∫°o ======
# model_test = AntiSpoofPredict(DEVICE_ID)
# image_cropper = CropImage()
# h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

# # ====== Load FAISS index ======
# print("üìÇ ƒêang t·∫£i FAISS index v√† student_ids...")
# index = faiss.read_index(FAISS_PATH)
# with open(IDS_PATH, "rb") as f:
#     student_ids = pickle.load(f)
# print(f"‚úÖ ƒê√£ load FAISS index ({index.ntotal} vectors)")

# # ====== Kh·ªüi t·∫°o InsightFace ======
# app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
# app.prepare(ctx_id=0, det_size=(320, 320))

# # ====== G·ª≠i d·ªØ li·ªáu theo l√¥ ======
# send_buffer = []
# send_lock = threading.Lock()
# send_interval = 3  # gi√¢y

# def send_data_batch():
#     while True:
#         time.sleep(send_interval)
#         with send_lock:
#             buffer_copy = send_buffer.copy()
#             send_buffer.clear()

#         for record in buffer_copy:
#             try:
#                 response = requests.post(API_URL, json=record)
#                 if response.status_code in [200, 201]:
#                     print(f"‚úÖ G·ª≠i th√†nh c√¥ng: {record['name']} l√∫c {record['timestamp']}")
#                 else:
#                     print(f"‚ùå L·ªói g·ª≠i: {response.status_code} - {response.text}")
#             except Exception as e:
#                 print(f"‚ö†Ô∏è G·ª≠i l·ªói: {e}")

# # Kh·ªüi ƒë·ªông lu·ªìng g·ª≠i
# threading.Thread(target=send_data_batch, daemon=True).start()

# # ====== H√†m ch·ªëng gi·∫£ m·∫°o ======
# def is_real_face(frame, bbox):
#     image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
#     param = {
#         "org_img": frame,
#         "bbox": image_bbox,
#         "scale": scale,
#         "out_w": w_input,
#         "out_h": h_input,
#         "crop": True if scale is not None else False,
#     }
#     spoof_input = image_cropper.crop(**param)
#     prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
#     label = np.argmax(prediction)
#     confidence = prediction[0][label] / 2
#     return label == 1, confidence

# # ====== Nh·∫≠n di·ªán khu√¥n m·∫∑t ======
# def recognize_face(face_embedding):
#     embedding = face_embedding.astype(np.float32).reshape(1, -1)
#     embedding /= np.linalg.norm(embedding)
#     D, I = index.search(embedding, 1)
#     distance = float(D[0][0])
#     idx = int(I[0][0])
#     if distance < FAISS_THRESHOLD:
#         return student_ids[idx], distance
#     return "Unknown", distance

# # ====== V·∫Ω nh√£n l√™n khung h√¨nh ======
# def draw_label(frame, bbox, label_text, color):
#     cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
#     cv2.putText(frame, label_text, (bbox[0], bbox[1] - 10),
#                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# # ====== M·ªü webcam ======
# cap = cv2.VideoCapture(0)
# if not cap.isOpened():
#     print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
#     exit()

# print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")

# # ====== Bi·∫øn th·ªëng k√™ ======
# frame_count = 0
# face_count = 0
# total_elapsed_time = 0.0
# total_face_time = 0.0
# last_spoof_check = 0
# spoof_result = None

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         print("‚ö†Ô∏è L·ªói khi ƒë·ªçc webcam.")
#         break

#     frame_start_time = time.perf_counter()
#     faces = app.get(frame)
#     face_count += len(faces)

#     for face in faces:
#         bbox = face.bbox.astype(int)

#         # Anti-spoofing m·ªói 2 gi√¢y
#         if time.time() - last_spoof_check > 2:
#             is_real, confidence = is_real_face(frame, bbox)
#             spoof_result = (is_real, confidence)
#             last_spoof_check = time.time()

#         is_real, confidence = spoof_result if spoof_result else (False, 0.0)

#         face_start_time = time.perf_counter()

#         if is_real:
#             identity, dist = recognize_face(face.embedding)
#             label_text = f"{identity} ({dist:.2f})"
#             color = (0, 255, 0)

#             if identity != "Unknown":
#                 payload = {
#                     "name": identity,
#                     "confidence": round(dist, 2),
#                     "real_face": 1.0,
#                     "timestamp": datetime.now().isoformat()
#                 }
#                 with send_lock:
#                     send_buffer.append(payload)
#         else:
#             label_text = f"Fake Face ({confidence:.2f})"
#             color = (0, 0, 255)

#         draw_label(frame, bbox, label_text, color)

#         face_time = time.perf_counter() - face_start_time
#         total_face_time += face_time

#     # ƒê·∫øm khung h√¨nh
#     frame_count += 1
#     elapsed = time.perf_counter() - frame_start_time
#     total_elapsed_time += elapsed

#     fps = f"FPS: {1 / elapsed:.2f}"
#     cv2.putText(frame, fps, (10, 30),
#                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

#     cv2.imshow("Anti-Spoof + Face Recognition", frame)
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         break

# # ====== Gi·∫£i ph√≥ng ======
# cap.release()
# cv2.destroyAllWindows()

# # ====== Th·ªëng k√™ k·∫øt qu·∫£ ======
# print("\n===== TH·ªêNG K√ä HI·ªÜU SU·∫§T =====")
# print(f"T·ªïng s·ªë khung h√¨nh:        {frame_count}")
# print(f"T·ªïng s·ªë khu√¥n m·∫∑t:         {face_count}")
# print(f"Th·ªùi gian ch·∫°y (gi√¢y):     {total_elapsed_time:.2f}s")
# print(f"FPS trung b√¨nh:            {frame_count / total_elapsed_time:.2f}")
# print(f"Th·ªùi gian trung b√¨nh/face: {total_face_time / face_count:.4f} gi√¢y (n·∫øu c√≥ face)")

# import time
# import cv2
# import numpy as np
# import faiss
# import pickle
# import os
# import warnings
# import requests
# import threading
# from datetime import datetime
# from insightface.app import FaceAnalysis
# from src.anti_spoof_predict import AntiSpoofPredict
# from src.generate_patches import CropImage
# from src.utility import parse_model_name
# import cloudinary
# import cloudinary.uploader

# warnings.filterwarnings('ignore')

# # ====== Cloudinary Config ======
# cloudinary.config(
#     cloud_name="dvc80qdie",
#     api_key="221435714784277",
#     api_secret="Zar2Kh6w0VBWp0rpQ5VYE-sbREI",
#     secure=True
# )

# # ====== C·∫•u h√¨nh ======
# MODEL_DIR = "./resources/anti_spoof_models"
# MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# DEVICE_ID = 0
# FAISS_PATH = "faiss_index/face_index.faiss"
# IDS_PATH = "faiss_index/student_ids.pkl"
# FAISS_THRESHOLD = 1.2
# API_URL = "http://localhost:5000/api/v1/exam-attendance/"

# # ====== Kh·ªüi t·∫°o m√¥ h√¨nh ch·ªëng gi·∫£ m·∫°o ======
# model_test = AntiSpoofPredict(DEVICE_ID)
# image_cropper = CropImage()
# h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

# # ====== Load FAISS index ======
# print("üìÇ ƒêang t·∫£i FAISS index v√† student_ids...")
# index = faiss.read_index(FAISS_PATH)
# with open(IDS_PATH, "rb") as f:
#     student_ids = pickle.load(f)
# print(f"‚úÖ ƒê√£ load FAISS index ({index.ntotal} vectors)")

# # ====== Kh·ªüi t·∫°o InsightFace ======
# app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
# app.prepare(ctx_id=0, det_size=(320, 320))

# # ====== G·ª≠i d·ªØ li·ªáu theo l√¥ ======
# send_buffer = []
# send_lock = threading.Lock()
# send_interval = 3  # gi√¢y

# def send_data_batch():
#     while True:
#         time.sleep(send_interval)
#         with send_lock:
#             buffer_copy = send_buffer.copy()
#             send_buffer.clear()

#         for record in buffer_copy:
#             try:
#                 response = requests.post(API_URL, json=record)
#                 if response.status_code in [200, 201]:
#                     print(f"‚úÖ G·ª≠i th√†nh c√¥ng: {record['name']} l√∫c {record['timestamp']}")
#                 else:
#                     print(f"‚ùå L·ªói g·ª≠i: {response.status_code} - {response.text}")
#             except Exception as e:
#                 print(f"‚ö†Ô∏è G·ª≠i l·ªói: {e}")

# # Kh·ªüi ƒë·ªông lu·ªìng g·ª≠i
# threading.Thread(target=send_data_batch, daemon=True).start()

# # ====== H√†m upload ·∫£nh gi·∫£ m·∫°o l√™n Cloudinary ======
# def upload_fake_face(frame, identity="unknown"):
#     timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
#     filename = f"fake_face_{identity}_{timestamp}.jpg"
#     filepath = f"/tmp/{filename}"
#     cv2.imwrite(filepath, frame)

#     try:
#         response = cloudinary.uploader.upload(filepath, folder="fake_faces/")
#         print(f"‚òÅÔ∏è ·∫¢nh gi·∫£ m·∫°o ƒë√£ upload: {response['secure_url']}")
#     except Exception as e:
#         print(f"‚ùå L·ªói khi upload ·∫£nh l√™n Cloudinary: {e}")

# # ====== H√†m ch·ªëng gi·∫£ m·∫°o ======
# def is_real_face(frame, bbox):
#     image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
#     param = {
#         "org_img": frame,
#         "bbox": image_bbox,
#         "scale": scale,
#         "out_w": w_input,
#         "out_h": h_input,
#         "crop": True if scale is not None else False,
#     }
#     spoof_input = image_cropper.crop(**param)
#     prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
#     label = np.argmax(prediction)
#     confidence = prediction[0][label] / 2
#     return label == 1, confidence

# # ====== Nh·∫≠n di·ªán khu√¥n m·∫∑t ======
# def recognize_face(face_embedding):
#     embedding = face_embedding.astype(np.float32).reshape(1, -1)
#     embedding /= np.linalg.norm(embedding)
#     D, I = index.search(embedding, 1)
#     distance = float(D[0][0])
#     idx = int(I[0][0])
#     if distance < FAISS_THRESHOLD:
#         return student_ids[idx], distance
#     return "Unknown", distance

# # ====== V·∫Ω nh√£n l√™n khung h√¨nh ======
# def draw_label(frame, bbox, label_text, color):
#     cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
#     cv2.putText(frame, label_text, (bbox[0], bbox[1] - 10),
#                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# # ====== M·ªü webcam ======
# cap = cv2.VideoCapture(0)
# if not cap.isOpened():
#     print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
#     exit()

# print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")

# # ====== Bi·∫øn th·ªëng k√™ ======
# frame_count = 0
# face_count = 0
# total_elapsed_time = 0.0
# total_face_time = 0.0
# last_spoof_check = 0
# spoof_result = None

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         print("‚ö†Ô∏è L·ªói khi ƒë·ªçc webcam.")
#         break

#     frame_start_time = time.perf_counter()
#     faces = app.get(frame)
#     face_count += len(faces)

#     for face in faces:
#         bbox = face.bbox.astype(int)

#         # Anti-spoofing m·ªói 2 gi√¢y
#         if time.time() - last_spoof_check > 2:
#             is_real, confidence = is_real_face(frame, bbox)
#             spoof_result = (is_real, confidence)
#             last_spoof_check = time.time()

#         is_real, confidence = spoof_result if spoof_result else (False, 0.0)

#         face_start_time = time.perf_counter()

#         if is_real:
#             identity, dist = recognize_face(face.embedding)
#             label_text = f"{identity} ({dist:.2f})"
#             color = (0, 255, 0)

#             if identity != "Unknown":
#                 payload = {
#                     "name": identity,
#                     "confidence": round(dist, 2),
#                     "real_face": 1.0,
#                     "timestamp": datetime.now().isoformat()
#                 }
#                 with send_lock:
#                     send_buffer.append(payload)
#         else:
#             label_text = f"Fake Face ({confidence:.2f})"
#             color = (0, 0, 255)
#             upload_fake_face(frame)

#         draw_label(frame, bbox, label_text, color)

#         face_time = time.perf_counter() - face_start_time
#         total_face_time += face_time

#     # ƒê·∫øm khung h√¨nh
#     frame_count += 1
#     elapsed = time.perf_counter() - frame_start_time
#     total_elapsed_time += elapsed

#     fps = f"FPS: {1 / elapsed:.2f}"
#     cv2.putText(frame, fps, (10, 30),
#                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

#     cv2.imshow("Anti-Spoof + Face Recognition", frame)
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         break

# # ====== Gi·∫£i ph√≥ng ======
# cap.release()
# cv2.destroyAllWindows()

# # ====== Th·ªëng k√™ k·∫øt qu·∫£ ======
# print("\n===== TH·ªêNG K√ä HI·ªÜU SU·∫§T =====")
# print(f"T·ªïng s·ªë khung h√¨nh:        {frame_count}")
# print(f"T·ªïng s·ªë khu√¥n m·∫∑t:         {face_count}")
# print(f"Th·ªùi gian ch·∫°y (gi√¢y):     {total_elapsed_time:.2f}s")
# print(f"FPS trung b√¨nh:            {frame_count / total_elapsed_time:.2f}")
# print(f"Th·ªùi gian trung b√¨nh/face: {total_face_time / face_count:.4f} gi√¢y (n·∫øu c√≥ face)")

# # # # import time
# # # # import cv2
# # # # import numpy as np
# # # # import faiss
# # # # import pickle
# # # # import os
# # # # import warnings
# # # # import requests
# # # # import threading
# # # # import io
# # # # from datetime import datetime
# # # # from insightface.app import FaceAnalysis
# # # # from src.anti_spoof_predict import AntiSpoofPredict
# # # # from src.generate_patches import CropImage
# # # # from src.utility import parse_model_name
# # # # import cloudinary
# # # # import cloudinary.uploader

# # # # warnings.filterwarnings('ignore')

# # # # # ====== Cloudinary Config ======
# # # # cloudinary.config(
# # # #     cloud_name="dvc80qdie",
# # # #     api_key="221435714784277",
# # # #     api_secret="Zar2Kh6w0VBWp0rpQ5VYE-sbREI",
# # # #     secure=True
# # # # )

# # # # # ====== C·∫•u h√¨nh ======
# # # # MODEL_DIR = "./resources/anti_spoof_models"
# # # # MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# # # # DEVICE_ID = 0
# # # # FAISS_PATH = "faiss_index/face_index.faiss"
# # # # IDS_PATH = "faiss_index/student_ids.pkl"
# # # # FAISS_THRESHOLD = 1.2
# # # # API_URL = "http://localhost:5000/api/v1/exam-attendance/"

# # # # # ====== Kh·ªüi t·∫°o m√¥ h√¨nh ch·ªëng gi·∫£ m·∫°o ======
# # # # model_test = AntiSpoofPredict(DEVICE_ID)
# # # # image_cropper = CropImage()
# # # # h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

# # # # # ====== Load FAISS index ======
# # # # print("üìÇ ƒêang t·∫£i FAISS index v√† student_ids...")
# # # # index = faiss.read_index(FAISS_PATH)
# # # # with open(IDS_PATH, "rb") as f:
# # # #     student_ids = pickle.load(f)
# # # # print(f"‚úÖ ƒê√£ load FAISS index ({index.ntotal} vectors)")

# # # # # ====== Kh·ªüi t·∫°o InsightFace ======
# # # # app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
# # # # app.prepare(ctx_id=0, det_size=(320, 320))

# # # # # ====== G·ª≠i d·ªØ li·ªáu theo l√¥ ======
# # # # send_buffer = []
# # # # send_lock = threading.Lock()
# # # # send_interval = 3  # gi√¢y

# # # # def send_data_batch():
# # # #     while True:
# # # #         time.sleep(send_interval)
# # # #         with send_lock:
# # # #             buffer_copy = send_buffer.copy()
# # # #             send_buffer.clear()

# # # #         for record in buffer_copy:
# # # #             try:
# # # #                 response = requests.post(API_URL, json=record)
# # # #                 if response.status_code in [200, 201]:
# # # #                     print(f"‚úÖ G·ª≠i th√†nh c√¥ng: {record['name']} l√∫c {record['timestamp']}")
# # # #                 else:
# # # #                     print(f"‚ùå L·ªói g·ª≠i: {response.status_code} - {response.text}")
# # # #             except Exception as e:
# # # #                 print(f"‚ö†Ô∏è G·ª≠i l·ªói: {e}")

# # # # # Kh·ªüi ƒë·ªông lu·ªìng g·ª≠i
# # # # threading.Thread(target=send_data_batch, daemon=True).start()

# # # # # ====== H√†m upload ·∫£nh gi·∫£ m·∫°o t·ª´ RAM, kh√¥ng ghi file ======
# # # # def upload_fake_face_async(frame, bbox, identity="unknown"):
# # # #     def do_upload():
# # # #         x1, y1, x2, y2 = bbox
# # # #         face_img = frame[y1:y2, x1:x2]

# # # #         # Resize ƒë·ªÉ nh·∫π h∆°n (tu·ª≥ ch·ªçn)
# # # #         face_img = cv2.resize(face_img, (160, 160))

# # # #         # Encode JPEG sang bytes
# # # #         success, buffer = cv2.imencode(".jpg", face_img)
# # # #         if not success:
# # # #             print("‚ö†Ô∏è Kh√¥ng encode ƒë∆∞·ª£c ·∫£nh.")
# # # #             return

# # # #         image_bytes = io.BytesIO(buffer.tobytes())

# # # #         try:
# # # #             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# # # #             response = cloudinary.uploader.upload(
# # # #                 image_bytes,
# # # #                 folder="fake_faces/",
# # # #                 public_id=f"fake_{identity}_{timestamp}",
# # # #                 resource_type="image"
# # # #             )
# # # #             print(f"‚òÅÔ∏è Upload th√†nh c√¥ng: {response['secure_url']}")
# # # #         except Exception as e:
# # # #             print(f"‚ùå Upload l·ªói: {e}")

# # # #     threading.Thread(target=do_upload, daemon=True).start()

# # # # # ====== H√†m ch·ªëng gi·∫£ m·∫°o ======
# # # # def is_real_face(frame, bbox):
# # # #     image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
# # # #     param = {
# # # #         "org_img": frame,
# # # #         "bbox": image_bbox,
# # # #         "scale": scale,
# # # #         "out_w": w_input,
# # # #         "out_h": h_input,
# # # #         "crop": True if scale is not None else False,
# # # #     }
# # # #     spoof_input = image_cropper.crop(**param)
# # # #     prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
# # # #     label = np.argmax(prediction)
# # # #     confidence = prediction[0][label] / 2
# # # #     return label == 1, confidence

# # # # # ====== Nh·∫≠n di·ªán khu√¥n m·∫∑t ======
# # # # def recognize_face(face_embedding):
# # # #     embedding = face_embedding.astype(np.float32).reshape(1, -1)
# # # #     embedding /= np.linalg.norm(embedding)
# # # #     D, I = index.search(embedding, 1)
# # # #     distance = float(D[0][0])
# # # #     idx = int(I[0][0])
# # # #     if distance < FAISS_THRESHOLD:
# # # #         return student_ids[idx], distance
# # # #     return "Unknown", distance

# # # # # ====== V·∫Ω nh√£n l√™n khung h√¨nh ======
# # # # def draw_label(frame, bbox, label_text, color):
# # # #     cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
# # # #     cv2.putText(frame, label_text, (bbox[0], bbox[1] - 10),
# # # #                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# # # # # ====== M·ªü webcam ======
# # # # cap = cv2.VideoCapture(0)
# # # # if not cap.isOpened():
# # # #     print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
# # # #     exit()

# # # # print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")

# # # # # ====== Bi·∫øn th·ªëng k√™ ======
# # # # frame_count = 0
# # # # face_count = 0
# # # # total_elapsed_time = 0.0
# # # # total_face_time = 0.0
# # # # last_spoof_check = 0
# # # # spoof_result = None

# # # # while True:
# # # #     ret, frame = cap.read()
# # # #     if not ret:
# # # #         print("‚ö†Ô∏è L·ªói khi ƒë·ªçc webcam.")
# # # #         break

# # # #     frame_start_time = time.perf_counter()
# # # #     faces = app.get(frame)
# # # #     face_count += len(faces)

# # # #     for face in faces:
# # # #         bbox = face.bbox.astype(int)

# # # #         # Anti-spoofing m·ªói 2 gi√¢y
# # # #         if time.time() - last_spoof_check > 2:
# # # #             is_real, confidence = is_real_face(frame, bbox)
# # # #             spoof_result = (is_real, confidence)
# # # #             last_spoof_check = time.time()

# # # #         is_real, confidence = spoof_result if spoof_result else (False, 0.0)

# # # #         face_start_time = time.perf_counter()

# # # #         if is_real:
# # # #             identity, dist = recognize_face(face.embedding)
# # # #             label_text = f"{identity} ({dist:.2f})"
# # # #             color = (0, 255, 0)

# # # #             if identity != "Unknown":
# # # #                 payload = {
# # # #                     "name": identity,
# # # #                     "confidence": round(dist, 2),
# # # #                     "real_face": 1.0,
# # # #                     "timestamp": datetime.now().isoformat()
# # # #                 }
# # # #                 with send_lock:
# # # #                     send_buffer.append(payload)
# # # #         else:
# # # #             label_text = f"Fake Face ({confidence:.2f})"
# # # #             color = (0, 0, 255)
# # # #             upload_fake_face_async(frame, bbox)

# # # #         draw_label(frame, bbox, label_text, color)

# # # #         face_time = time.perf_counter() - face_start_time
# # # #         total_face_time += face_time

# # # #     # ƒê·∫øm khung h√¨nh
# # # #     frame_count += 1
# # # #     elapsed = time.perf_counter() - frame_start_time
# # # #     total_elapsed_time += elapsed

# # # #     fps = f"FPS: {1 / elapsed:.2f}"
# # # #     cv2.putText(frame, fps, (10, 30),
# # # #                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

# # # #     cv2.imshow("Anti-Spoof + Face Recognition", frame)
# # # #     if cv2.waitKey(1) & 0xFF == ord('q'):
# # # #         break

# # # # # ====== Gi·∫£i ph√≥ng ======
# # # # cap.release()
# # # # cv2.destroyAllWindows()

# # # # # ====== Th·ªëng k√™ k·∫øt qu·∫£ ======
# # # # print("\n===== TH·ªêNG K√ä HI·ªÜU SU·∫§T =====")
# # # # print(f"T·ªïng s·ªë khung h√¨nh:        {frame_count}")
# # # # print(f"T·ªïng s·ªë khu√¥n m·∫∑t:         {face_count}")
# # # # print(f"Th·ªùi gian ch·∫°y (gi√¢y):     {total_elapsed_time:.2f}s")
# # # # print(f"FPS trung b√¨nh:            {frame_count / total_elapsed_time:.2f}")
# # # # print(f"Th·ªùi gian trung b√¨nh/face: {total_face_time / face_count:.4f} gi√¢y (n·∫øu c√≥ face)")


# # # import time
# # # import cv2
# # # import numpy as np
# # # import faiss
# # # import pickle
# # # import os
# # # import warnings
# # # import requests
# # # import threading
# # # import io
# # # import queue
# # # from datetime import datetime
# # # from insightface.app import FaceAnalysis
# # # from src.anti_spoof_predict import AntiSpoofPredict
# # # from src.generate_patches import CropImage
# # # from src.utility import parse_model_name
# # # import cloudinary
# # # import cloudinary.uploader

# # # warnings.filterwarnings('ignore')

# # # # ====== Cloudinary Config ======
# # # cloudinary.config(
# # #     cloud_name="dvc80qdie",
# # #     api_key="221435714784277",
# # #     api_secret="Zar2Kh6w0VBWp0rpQ5VYE-sbREI",
# # #     secure=True
# # # )

# # # # ====== C·∫•u h√¨nh ======
# # # MODEL_DIR = "./resources/anti_spoof_models"
# # # MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# # # DEVICE_ID = 0
# # # FAISS_PATH = "faiss_index/face_index.faiss"
# # # IDS_PATH = "faiss_index/student_ids.pkl"
# # # FAISS_THRESHOLD = 1.2
# # # API_URL = "http://localhost:5000/api/v1/exam-attendance/"
# # # CAMERA_RESOLUTION = (640, 480) # Gi·∫£m ƒë·ªô ph√¢n gi·∫£i ƒë·ªÉ tƒÉng t·ªëc

# # # # --- KH·ªûI T·∫†O C√ÅC H√ÄNG ƒê·ª¢I (QUEUES) ---
# # # frames_queue = queue.Queue(maxsize=2) # H√†ng ƒë·ª£i ch·ª©a khung h√¨nh th√¥ t·ª´ camera
# # # results_queue = queue.Queue(maxsize=2) # H√†ng ƒë·ª£i ch·ª©a k·∫øt qu·∫£ cu·ªëi c√πng ƒë·ªÉ hi·ªÉn th·ªã
# # # upload_queue = queue.Queue(maxsize=10) # H√†ng ƒë·ª£i ch·ª©a ·∫£nh gi·∫£ m·∫°o ƒë·ªÉ upload
# # # api_send_buffer = []
# # # api_send_lock = threading.Lock()


# # # # ====== LU·ªíNG 1: UPLOADER WORKER (Kh√¥ng ƒë·ªïi) ======
# # # def uploader_worker():
# # #     while True:
# # #         try:
# # #             face_img, identity = upload_queue.get()
# # #             success, buffer = cv2.imencode(".jpg", face_img)
# # #             if not success: continue
            
# # #             image_bytes = io.BytesIO(buffer.tobytes())
# # #             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# # #             cloudinary.uploader.upload(
# # #                 image_bytes,
# # #                 folder="fake_faces/",
# # #                 public_id=f"fake_{identity}_{timestamp}",
# # #                 resource_type="image"
# # #             )
# # #             # print(f"‚òÅÔ∏è Uploaded fake face.")
# # #             upload_queue.task_done()
# # #         except Exception as e:
# # #             print(f"‚ùå L·ªói upload Cloudinary: {e}")

# # # # ====== LU·ªíNG 2: API SENDER WORKER (Kh√¥ng ƒë·ªïi) ======
# # # def api_sender_worker():
# # #     while True:
# # #         time.sleep(3)
# # #         with api_send_lock:
# # #             if not api_send_buffer: continue
# # #             buffer_copy = api_send_buffer.copy()
# # #             api_send_buffer.clear()

# # #         for record in buffer_copy:
# # #             try:
# # #                 requests.post(API_URL, json=record, timeout=5)
# # #                 # print(f"‚úÖ Sent attendance: {record['name']}")
# # #             except Exception as e:
# # #                 print(f"‚ö†Ô∏è L·ªói g·ª≠i API: {e}")


# # # # ====== LU·ªíNG 3: PROCESSING WORKER (C√îNG NH√ÇN X·ª¨ L√ù CH√çNH) ======
# # # def processing_worker():
# # #     # M·ªói lu·ªìng ph·∫£i kh·ªüi t·∫°o model c·ªßa ri√™ng n√≥
# # #     app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
# # #     app.prepare(ctx_id=0, det_size=(320, 320))
    
# # #     model_test = AntiSpoofPredict(DEVICE_ID)
# # #     image_cropper = CropImage()
# # #     h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

# # #     index = faiss.read_index(FAISS_PATH)
# # #     with open(IDS_PATH, "rb") as f:
# # #         student_ids = pickle.load(f)

# # #     # --- C√°c h√†m helper b√™n trong lu·ªìng ---
# # #     def is_real_face(frame, bbox):
# # #         image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
# # #         param = {"org_img": frame, "bbox": image_bbox, "scale": scale, "out_w": w_input, "out_h": h_input, "crop": True}
# # #         if param["bbox"][2] == 0 or param["bbox"][3] == 0: return False, 0.0
# # #         spoof_input = image_cropper.crop(**param)
# # #         prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
# # #         label = np.argmax(prediction)
# # #         return label == 1, prediction[0][label] / 2

# # #     def recognize_face(face_embedding):
# # #         embedding = face_embedding.astype(np.float32).reshape(1, -1)
# # #         embedding /= np.linalg.norm(embedding)
# # #         D, I = index.search(embedding, 1)
# # #         if D[0][0] < FAISS_THRESHOLD:
# # #             return student_ids[int(I[0][0])], float(D[0][0])
# # #         return "Unknown", float(D[0][0])

# # #     # --- V√≤ng l·∫∑p ch√≠nh c·ªßa lu·ªìng x·ª≠ l√Ω ---
# # #     while True:
# # #         try:
# # #             frame = frames_queue.get(timeout=1)
# # #             processed_results = []
            
# # #             # T√°c v·ª• n·∫∑ng: ph√°t hi·ªán khu√¥n m·∫∑t
# # #             faces = app.get(frame)

# # #             for face in faces:
# # #                 bbox = face.bbox.astype(int)
                
# # #                 # T√°c v·ª• n·∫∑ng: anti-spoofing
# # #                 is_real, confidence = is_real_face(frame, bbox)

# # #                 if is_real:
# # #                     # T√°c v·ª• n·∫∑ng: nh·∫≠n d·∫°ng
# # #                     identity, dist = recognize_face(face.embedding)
# # #                     label_text = f"{identity} ({dist:.2f})"
# # #                     color = (0, 255, 0)

# # #                     if identity != "Unknown":
# # #                         payload = {"name": identity, "timestamp": datetime.now().isoformat()}
# # #                         with api_send_lock:
# # #                             # Tr√°nh g·ª≠i tr√πng l·∫∑p qu√° nhanh
# # #                             if not any(p['name'] == identity for p in api_send_buffer):
# # #                                 api_send_buffer.append(payload)
# # #                 else:
# # #                     label_text = f"Fake Face ({confidence:.2f})"
# # #                     color = (0, 0, 255)
# # #                     if not upload_queue.full():
# # #                         x1, y1, x2, y2 = bbox
# # #                         face_img = frame[y1:y2, x1:x2]
# # #                         face_img_resized = cv2.resize(face_img, (160, 160))
# # #                         upload_queue.put((face_img_resized, "unknown"))

# # #                 processed_results.append({'bbox': bbox, 'label': label_text, 'color': color})
            
# # #             # ƒê∆∞a k·∫øt qu·∫£ ƒë√£ x·ª≠ l√Ω v√†o h√†ng ƒë·ª£i k·∫øt qu·∫£
# # #             results_queue.put(processed_results)
# # #             frames_queue.task_done()

# # #         except queue.Empty:
# # #             continue # ƒê·ª£i khung h√¨nh m·ªõi
# # #         except Exception as e:
# # #             print(f"‚ùå L·ªói trong lu·ªìng x·ª≠ l√Ω: {e}")


# # # # ====== LU·ªíNG CH√çNH (CAMERA & DISPLAY) - SI√äU NH·∫∏ ======
# # # def main():
# # #     # Kh·ªüi ƒë·ªông t·∫•t c·∫£ c√°c lu·ªìng worker
# # #     threading.Thread(target=processing_worker, daemon=True).start()
# # #     threading.Thread(target=uploader_worker, daemon=True).start()
# # #     threading.Thread(target=api_sender_worker, daemon=True).start()

# # #     print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")
# # #     cap = cv2.VideoCapture(0)
# # #     if not cap.isOpened():
# # #         print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
# # #         return
        
# # #     cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_RESOLUTION[0])
# # #     cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_RESOLUTION[1])
    
# # #     start_time = time.time()
# # #     frame_count = 0
    
# # #     while True:
# # #         ret, frame = cap.read()
# # #         if not ret:
# # #             break

# # #         # ƒê∆∞a khung h√¨nh v√†o h√†ng ƒë·ª£i x·ª≠ l√Ω m√† kh√¥ng ch·ªù ƒë·ª£i
# # #         if not frames_queue.full():
# # #             frames_queue.put(frame)

# # #         # L·∫•y k·∫øt qu·∫£ t·ª´ h√†ng ƒë·ª£i k·∫øt qu·∫£ (n·∫øu c√≥)
# # #         try:
# # #             results = results_queue.get_nowait()
# # #             for res in results:
# # #                 bbox = res['bbox']
# # #                 label = res['label']
# # #                 color = res['color']
# # #                 cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
# # #                 cv2.putText(frame, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
# # #             results_queue.task_done()
# # #         except queue.Empty:
# # #             pass # Kh√¥ng c√≥ k·∫øt qu·∫£ m·ªõi, c·ª© hi·ªÉn th·ªã khung h√¨nh hi·ªán t·∫°i

# # #         # T√≠nh to√°n v√† hi·ªÉn th·ªã FPS
# # #         frame_count += 1
# # #         elapsed_time = time.time() - start_time
# # #         fps = frame_count / elapsed_time
# # #         cv2.putText(frame, f"FPS: {fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
# # #         cv2.imshow("Realtime Recognition", frame)

# # #         if cv2.waitKey(1) & 0xFF == ord('q'):
# # #             break

# # #     cap.release()
# # #     cv2.destroyAllWindows()

# # # if __name__ == '__main__':
# # #     main()




























# # # # import time
# # # # import cv2
# # # # import numpy as np
# # # # import faiss
# # # # import pickle
# # # # import os
# # # # import warnings
# # # # import requests
# # # # import threading
# # # # import io
# # # # import queue
# # # # from datetime import datetime
# # # # from insightface.app import FaceAnalysis
# # # # from src.anti_spoof_predict import AntiSpoofPredict
# # # # from src.generate_patches import CropImage
# # # # from src.utility import parse_model_name
# # # # import cloudinary
# # # # import cloudinary.uploader

# # # # warnings.filterwarnings('ignore')

# # # # # ====== Cloudinary Config ======
# # # # cloudinary.config(
# # # #     cloud_name="dvc80qdie",
# # # #     api_key="221435714784277",
# # # #     api_secret="Zar2Kh6w0VBWp0rpQ5VYE-sbREI",
# # # #     secure=True
# # # # )

# # # # # ====== C·∫•u h√¨nh ======
# # # # MODEL_DIR = "./resources/anti_spoof_models"
# # # # MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# # # # DEVICE_ID = 0
# # # # FAISS_PATH = "faiss_index/face_index.faiss"
# # # # IDS_PATH = "faiss_index/student_ids.pkl"
# # # # FAISS_THRESHOLD = 1.2
# # # # API_URL = "http://localhost:5000/api/v1/exam-attendance/"
# # # # CAMERA_RESOLUTION = (640, 480)

# # # # # --- KH·ªûI T·∫†O C√ÅC H√ÄNG ƒê·ª¢I (QUEUES) ---
# # # # frames_queue = queue.Queue(maxsize=1)  # Ch·ªâ c·∫ßn buffer 1 frame ƒë·ªÉ x·ª≠ l√Ω
# # # # results_queue = queue.Queue(maxsize=1) # H√†ng ƒë·ª£i ch·ª©a (khung h√¨nh, k·∫øt qu·∫£) ƒë√£ x·ª≠ l√Ω
# # # # upload_queue = queue.Queue(maxsize=10) # H√†ng ƒë·ª£i ch·ª©a (frame, bbox) ƒë·ªÉ upload
# # # # api_send_buffer = []
# # # # api_send_lock = threading.Lock()

# # # # # ====== LU·ªíNG 1: UPLOADER WORKER - C·∫£i ti·∫øn ƒë·ªÉ c·∫Øt ·∫£nh t·∫°i ƒë√¢y ======
# # # # def uploader_worker():
# # # #     while True:
# # # #         try:
# # # #             # <<< THAY ƒê·ªîI: Nh·∫≠n c·∫£ frame v√† bbox ƒë·ªÉ ƒë·∫£m b·∫£o c·∫Øt ƒë√∫ng
# # # #             frame, bbox, identity = upload_queue.get()

# # # #             # C·∫Øt khu√¥n m·∫∑t t·ª´ frame
# # # #             x1, y1, x2, y2 = bbox
# # # #             face_img = frame[y1:y2, x1:x2]

# # # #             # Ki·ªÉm tra xem c·∫Øt c√≥ th√†nh c√¥ng kh√¥ng
# # # #             if face_img.size == 0:
# # # #                 print("‚ö†Ô∏è B·ªè qua ·∫£nh gi·∫£ m·∫°o r·ªóng.")
# # # #                 continue

# # # #             face_img_resized = cv2.resize(face_img, (160, 160))
# # # #             success, buffer = cv2.imencode(".jpg", face_img_resized)
# # # #             if not success: continue

# # # #             image_bytes = io.BytesIO(buffer.tobytes())
# # # #             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# # # #             cloudinary.uploader.upload(
# # # #                 image_bytes,
# # # #                 folder="fake_faces/",
# # # #                 public_id=f"fake_{identity}_{timestamp}",
# # # #                 resource_type="image"
# # # #             )
# # # #             # print(f"‚òÅÔ∏è ƒê√£ upload ·∫£nh gi·∫£ m·∫°o.")
# # # #             upload_queue.task_done()
# # # #         except Exception as e:
# # # #             print(f"‚ùå L·ªói upload Cloudinary: {e}")

# # # # # ====== LU·ªíNG 2: API SENDER WORKER (Kh√¥ng ƒë·ªïi) ======
# # # # def api_sender_worker():
# # # #     while True:
# # # #         time.sleep(3)
# # # #         with api_send_lock:
# # # #             if not api_send_buffer: continue
# # # #             buffer_copy = api_send_buffer.copy()
# # # #             api_send_buffer.clear()

# # # #         for record in buffer_copy:
# # # #             try:
# # # #                 requests.post(API_URL, json=record, timeout=5)
# # # #             except Exception as e:
# # # #                 print(f"‚ö†Ô∏è L·ªói g·ª≠i API: {e}")

# # # # # ====== LU·ªíNG 3: PROCESSING WORKER (C√îNG NH√ÇN X·ª¨ L√ù CH√çNH) ======
# # # # def processing_worker():
# # # #     app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
# # # #     app.prepare(ctx_id=0, det_size=(320, 320))
# # # #     model_test = AntiSpoofPredict(DEVICE_ID)
# # # #     image_cropper = CropImage()
# # # #     h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)
# # # #     index = faiss.read_index(FAISS_PATH)
# # # #     with open(IDS_PATH, "rb") as f:
# # # #         student_ids = pickle.load(f)

# # # #     def is_real_face(frame, bbox):
# # # #         image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
# # # #         param = {"org_img": frame, "bbox": image_bbox, "scale": scale, "out_w": w_input, "out_h": h_input, "crop": True}
# # # #         if param["bbox"][2] <= 0 or param["bbox"][3] <= 0: return False, 0.0
# # # #         spoof_input = image_cropper.crop(**param)
# # # #         prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
# # # #         label = np.argmax(prediction)
# # # #         return label == 1, prediction[0][label] / 2

# # # #     def recognize_face(face_embedding):
# # # #         embedding = face_embedding.astype(np.float32).reshape(1, -1)
# # # #         embedding /= np.linalg.norm(embedding)
# # # #         D, I = index.search(embedding, 1)
# # # #         if D[0][0] < FAISS_THRESHOLD:
# # # #             return student_ids[int(I[0][0])], float(D[0][0])
# # # #         return "Unknown", float(D[0][0])

# # # #     while True:
# # # #         try:
# # # #             frame = frames_queue.get(timeout=1)
# # # #             processed_results = []
# # # #             faces = app.get(frame)

# # # #             for face in faces:
# # # #                 bbox = face.bbox.astype(int)
# # # #                 is_real, confidence = is_real_face(frame, bbox)

# # # #                 if is_real:
# # # #                     identity, dist = recognize_face(face.embedding)
# # # #                     label_text = f"{identity} ({dist:.2f})"
# # # #                     color = (0, 255, 0)
# # # #                     if identity != "Unknown":
# # # #                         payload = {"name": identity, "timestamp": datetime.now().isoformat()}
# # # #                         with api_send_lock:
# # # #                             if not any(p['name'] == identity for p in api_send_buffer):
# # # #                                 api_send_buffer.append(payload)
# # # #                 else:
# # # #                     label_text = f"Fake Face ({confidence:.2f})"
# # # #                     color = (0, 0, 255)
# # # #                     if not upload_queue.full():
# # # #                         # <<< THAY ƒê·ªîI QUAN TR·ªåNG: G·ª≠i c·∫£ frame v√† bbox
# # # #                         # ƒë·ªÉ lu·ªìng uploader t·ª± c·∫Øt, ƒë·∫£m b·∫£o kh√¥ng l·ªói
# # # #                         upload_queue.put((frame.copy(), bbox, "unknown"))

# # # #                 processed_results.append({'bbox': bbox, 'label': label_text, 'color': color})

# # # #             # <<< THAY ƒê·ªîI QUAN TR·ªåNG: G·ª≠i c·∫£ FRAME v√† K·∫æT QU·∫¢ c·ªßa n√≥ ƒëi
# # # #             results_queue.put((frame, processed_results))
# # # #             frames_queue.task_done()
# # # #         except queue.Empty:
# # # #             continue
# # # #         except Exception as e:
# # # #             print(f"‚ùå L·ªói trong lu·ªìng x·ª≠ l√Ω: {e}", exc_info=True)


# # # # # ====== LU·ªíNG CH√çNH (CAMERA & DISPLAY) - ƒê·ªíNG B·ªò H√ìA ======
# # # # def main():
# # # #     threading.Thread(target=processing_worker, daemon=True).start()
# # # #     threading.Thread(target=uploader_worker, daemon=True).start()
# # # #     threading.Thread(target=api_sender_worker, daemon=True).start()

# # # #     print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")
# # # #     cap = cv2.VideoCapture(0)
# # # #     if not cap.isOpened():
# # # #         print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
# # # #         return

# # # #     cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_RESOLUTION[0])
# # # #     cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_RESOLUTION[1])

# # # #     last_processed_frame = None
# # # #     processing_fps = 0
# # # #     frame_times = queue.Queue()

# # # #     while True:
# # # #         ret, frame = cap.read()
# # # #         if not ret:
# # # #             break

# # # #         # ƒê∆∞a khung h√¨nh v√†o h√†ng ƒë·ª£i x·ª≠ l√Ω
# # # #         if not frames_queue.full():
# # # #             frames_queue.put(frame)

# # # #         # L·∫•y k·∫øt qu·∫£ (frame + bboxes) t·ª´ h√†ng ƒë·ª£i k·∫øt qu·∫£
# # # #         try:
# # # #             # <<< THAY ƒê·ªîI QUAN TR·ªåNG: Nh·∫≠n c·∫£ frame v√† k·∫øt qu·∫£
# # # #             processed_frame, results = results_queue.get_nowait()
            
# # # #             # V·∫Ω k·∫øt qu·∫£ l√™n ƒê√öNG khung h√¨nh m√† n√≥ ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
# # # #             for res in results:
# # # #                 bbox, label, color = res['bbox'], res['label'], res['color']
# # # #                 cv2.rectangle(processed_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
# # # #                 cv2.putText(processed_frame, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
# # # #             # T√≠nh to√°n FPS d·ª±a tr√™n t·ªëc ƒë·ªô x·ª≠ l√Ω
# # # #             now = time.time()
# # # #             frame_times.put(now)
# # # #             while frame_times.qsize() > 20:
# # # #                 frame_times.get()
# # # #             if frame_times.qsize() > 1:
# # # #                 processing_fps = (frame_times.qsize() -1) / (now - frame_times.queue[0])
            
# # # #             # C·∫≠p nh·∫≠t khung h√¨nh ƒë·ªÉ hi·ªÉn th·ªã
# # # #             last_processed_frame = processed_frame
# # # #             results_queue.task_done()

# # # #         except queue.Empty:
# # # #             pass # Kh√¥ng c√≥ k·∫øt qu·∫£ m·ªõi, ti·∫øp t·ª•c hi·ªÉn th·ªã khung h√¨nh c≈©

# # # #         # Hi·ªÉn th·ªã khung h√¨nh cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
# # # #         if last_processed_frame is not None:
# # # #             # Hi·ªÉn th·ªã FPS x·ª≠ l√Ω (con s·ªë th·∫≠t s·ª± quan tr·ªçng)
# # # #             cv2.putText(last_processed_frame, f"Processing FPS: {processing_fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
# # # #             cv2.imshow("Realtime Recognition", last_processed_frame)

# # # #         if cv2.waitKey(1) & 0xFF == ord('q'):
# # # #             break

# # # #     cap.release()
# # # #     cv2.destroyAllWindows()


# # # # if __name__ == '__main__':
# # # #     main()

# # import time
# # import cv2
# # import numpy as np
# # import faiss
# # import pickle
# # import os
# # import warnings
# # import requests
# # import threading
# # import io
# # import queue
# # from datetime import datetime
# # from insightface.app import FaceAnalysis
# # from src.anti_spoof_predict import AntiSpoofPredict
# # from src.generate_patches import CropImage
# # from src.utility import parse_model_name
# # import cloudinary
# # import cloudinary.uploader

# # warnings.filterwarnings('ignore')

# # # ====== Cloudinary Config ======
# # cloudinary.config(
# #     cloud_name="dvc80qdie",
# #     api_key="221435714784277",
# #     api_secret="Zar2Kh6w0VBWp0rpQ5VYE-sbREI",
# #     secure=True
# # )

# # # ====== C·∫•u h√¨nh ======
# # MODEL_DIR = "./resources/anti_spoof_models"
# # MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# # DEVICE_ID = 0
# # FAISS_PATH = "faiss_index/face_index.faiss"
# # IDS_PATH = "faiss_index/student_ids.pkl"
# # FAISS_THRESHOLD = 1.2
# # API_URL = "http://localhost:5000/api/v1/exam-attendance/"
# # CAMERA_RESOLUTION = (640, 480)

# # frames_queue = queue.Queue(maxsize=2)
# # results_queue = queue.Queue(maxsize=2)
# # upload_queue = queue.Queue(maxsize=10)
# # api_send_buffer = []
# # api_send_lock = threading.Lock()


# # # ====== Lu·ªìng Upload Cloudinary ======
# # def uploader_worker():
# #     while True:
# #         try:
# #             face_img, identity = upload_queue.get()
# #             success, buffer = cv2.imencode(".jpg", face_img)
# #             if not success:
# #                 continue

# #             image_bytes = io.BytesIO(buffer.tobytes())
# #             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# #             cloudinary.uploader.upload(
# #                 image_bytes,
# #                 folder="fake_faces/",
# #                 public_id=f"fake_{identity}_{timestamp}",
# #                 resource_type="image"
# #             )
# #             upload_queue.task_done()
# #         except Exception as e:
# #             print(f"‚ùå L·ªói upload Cloudinary: {e}")

# # # ====== Lu·ªìng G·ª≠i API ======
# # def api_sender_worker():
# #     while True:
# #         time.sleep(3)
# #         with api_send_lock:
# #             if not api_send_buffer:
# #                 continue
# #             buffer_copy = api_send_buffer.copy()
# #             api_send_buffer.clear()

# #         for record in buffer_copy:
# #             try:
# #                 requests.post(API_URL, json=record, timeout=5)
# #             except Exception as e:
# #                 print(f"‚ö†Ô∏è L·ªói g·ª≠i API: {e}")

# # # ====== Lu·ªìng X·ª≠ L√Ω Ch√≠nh ======
# # def processing_worker():
# #     app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
# #     app.prepare(ctx_id=0, det_size=(320, 320))

# #     model_test = AntiSpoofPredict(DEVICE_ID)
# #     image_cropper = CropImage()
# #     h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

# #     index = faiss.read_index(FAISS_PATH)
# #     with open(IDS_PATH, "rb") as f:
# #         student_ids = pickle.load(f)

# #     def is_real_face(frame, bbox):
# #         image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
# #         param = {"org_img": frame, "bbox": image_bbox, "scale": scale, "out_w": w_input, "out_h": h_input, "crop": True}
# #         if param["bbox"][2] == 0 or param["bbox"][3] == 0:
# #             return False, 0.0
# #         spoof_input = image_cropper.crop(**param)
# #         prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
# #         label = np.argmax(prediction)
# #         return label == 1, prediction[0][label] / 2

# #     def recognize_face(face_embedding):
# #         embedding = face_embedding.astype(np.float32).reshape(1, -1)
# #         embedding /= np.linalg.norm(embedding)
# #         D, I = index.search(embedding, 1)
# #         if D[0][0] < FAISS_THRESHOLD:
# #             return student_ids[int(I[0][0])], float(D[0][0])
# #         return "Unknown", float(D[0][0])

# #     while True:
# #         try:
# #             frame = frames_queue.get(timeout=1)
# #             processed_results = []
# #             faces = app.get(frame)

# #             for face in faces:
# #                 bbox = face.bbox.astype(int)
# #                 is_real, confidence = is_real_face(frame, bbox)

# #                 if is_real:
# #                     identity, dist = recognize_face(face.embedding)
# #                     label_text = f"{identity} ({dist:.2f})"
# #                     color = (0, 255, 0)

# #                     if identity != "Unknown":
# #                         payload = {"name": identity, "timestamp": datetime.now().isoformat()}
# #                         with api_send_lock:
# #                             if not any(p['name'] == identity for p in api_send_buffer):
# #                                 api_send_buffer.append(payload)
# #                 else:
# #                     label_text = f"Fake Face ({confidence:.2f})"
# #                     color = (0, 0, 255)

# #                     # G·ª≠i to√†n b·ªô frame ch·ª© kh√¥ng ch·ªâ crop khu√¥n m·∫∑t
# #                     if not upload_queue.full():
# #                         full_img = cv2.resize(frame, (640, 480))
# #                         upload_queue.put((full_img, "unknown"))

# #                 processed_results.append({'bbox': bbox, 'label': label_text, 'color': color})

# #             results_queue.put(processed_results)
# #             frames_queue.task_done()
# #         except queue.Empty:
# #             continue
# #         except Exception as e:
# #             print(f"‚ùå L·ªói trong lu·ªìng x·ª≠ l√Ω: {e}")

# # # ====== Main Loop (Camera & Display) ======
# # def main():
# #     threading.Thread(target=processing_worker, daemon=True).start()
# #     threading.Thread(target=uploader_worker, daemon=True).start()
# #     threading.Thread(target=api_sender_worker, daemon=True).start()

# #     print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")
# #     cap = cv2.VideoCapture(0)
# #     if not cap.isOpened():
# #         print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
# #         return

# #     cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_RESOLUTION[0])
# #     cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_RESOLUTION[1])

# #     start_time = time.time()
# #     frame_count = 0
# #     static_results = []

# #     while True:
# #         ret, frame = cap.read()
# #         if not ret:
# #             break

# #         if not frames_queue.full():
# #             frames_queue.put(frame)

# #         try:
# #             new_results = results_queue.get_nowait()
# #             static_results = new_results
# #             results_queue.task_done()
# #         except queue.Empty:
# #             pass

# #         for res in static_results:
# #             bbox = res['bbox']
# #             label = res['label']
# #             color = res['color']
# #             cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
# #             cv2.putText(frame, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# #         frame_count += 1
# #         elapsed_time = time.time() - start_time
# #         fps = frame_count / elapsed_time
# #         cv2.putText(frame, f"FPS: {fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

# #         cv2.imshow("Realtime Recognition", frame)

# #         if cv2.waitKey(1) & 0xFF == ord('q'):
# #             break

# #     cap.release()
# #     cv2.destroyAllWindows()

# # if __name__ == '__main__':
# #     main()















# ===================================================

# import time
# import cv2
# import numpy as np
# import faiss
# import pickle
# import os
# import warnings
# import requests
# import threading
# import io
# import queue
# from datetime import datetime
# from insightface.app import FaceAnalysis
# from src.anti_spoof_predict import AntiSpoofPredict
# from src.generate_patches import CropImage
# from src.utility import parse_model_name
# import cloudinary
# import cloudinary.uploader

# warnings.filterwarnings('ignore')

# # ====== Cloudinary Config ======
# cloudinary.config(
#     cloud_name="dvc80qdie",
#     api_key="221435714784277",
#     api_secret="Zar2Kh6w0VBWp0rpQ5VYE-sbREI",
#     secure=True
# )

# # ====== C·∫•u h√¨nh ======
# MODEL_DIR = "./resources/anti_spoof_models"
# MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# DEVICE_ID = 0
# FAISS_PATH = "faiss_index/face_index.faiss"
# IDS_PATH = "faiss_index/student_ids.pkl"
# FAISS_THRESHOLD = 1.2
# API_URL = "http://localhost:5000/api/v1/exam-attendance/"
# CAMERA_RESOLUTION = (640, 480)

# frames_queue = queue.Queue(maxsize=2)
# results_queue = queue.Queue(maxsize=2)
# upload_queue = queue.Queue(maxsize=10)
# api_send_buffer = []
# api_send_lock = threading.Lock()

# # ====== Lu·ªìng Upload Cloudinary ======
# def uploader_worker():
#     while True:
#         try:
#             face_img, identity = upload_queue.get()
#             success, buffer = cv2.imencode(".jpg", face_img)
#             if not success:
#                 upload_queue.task_done()
#                 continue

#             image_bytes = io.BytesIO(buffer.tobytes())
#             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
#             cloudinary.uploader.upload(
#                 image_bytes,
#                 folder="fake_faces/",
#                 public_id=f"fake_{identity}_{timestamp}",
#                 resource_type="image"
#             )
#             upload_queue.task_done()
#         except Exception as e:
#             print(f"‚ùå L·ªói upload Cloudinary: {e}")

# # ====== Lu·ªìng G·ª≠i API ======
# def api_sender_worker():
#     while True:
#         time.sleep(3)
#         with api_send_lock:
#             if not api_send_buffer:
#                 continue
#             buffer_copy = api_send_buffer.copy()
#             api_send_buffer.clear()

#         for record in buffer_copy:
#             try:
#                 requests.post(API_URL, json=record, timeout=5)
#             except Exception as e:
#                 print(f"‚ö†Ô∏è L·ªói g·ª≠i API: {e}")

# # ====== Lu·ªìng X·ª≠ L√Ω Ch√≠nh ======
# def processing_worker():
#     app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
#     app.prepare(ctx_id=0, det_size=(320, 320))

#     model_test = AntiSpoofPredict(DEVICE_ID)
#     image_cropper = CropImage()
#     h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

#     index = faiss.read_index(FAISS_PATH)
#     with open(IDS_PATH, "rb") as f:
#         student_ids = pickle.load(f)

#     last_fake_upload_time = 0  # Gi·ªõi h·∫°n upload ·∫£nh gi·∫£

#     def is_real_face(frame, bbox):
#         image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
#         param = {"org_img": frame, "bbox": image_bbox, "scale": scale, "out_w": w_input, "out_h": h_input, "crop": True}
#         if param["bbox"][2] == 0 or param["bbox"][3] == 0:
#             return False, 0.0
#         spoof_input = image_cropper.crop(**param)
#         prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
#         label = np.argmax(prediction)
#         return label == 1, prediction[0][label] / 2

#     def recognize_face(face_embedding):
#         embedding = face_embedding.astype(np.float32).reshape(1, -1)
#         embedding /= np.linalg.norm(embedding)
#         D, I = index.search(embedding, 1)
#         if D[0][0] < FAISS_THRESHOLD:
#             return student_ids[int(I[0][0])], float(D[0][0])
#         return "Unknown", float(D[0][0])

#     while True:
#         try:
#             frame = frames_queue.get(timeout=1)
#             processed_results = []
#             faces = app.get(frame)

#             for face in faces:
#                 bbox = face.bbox.astype(int)
#                 is_real, confidence = is_real_face(frame, bbox)

#                 if is_real:
#                     identity, dist = recognize_face(face.embedding)
#                     label_text = f"{identity} ({dist:.2f})"
#                     color = (0, 255, 0)

#                     if identity != "Unknown":
#                         payload = {"name": identity, "timestamp": datetime.now().isoformat()}
#                         with api_send_lock:
#                             if not any(p['name'] == identity for p in api_send_buffer):
#                                 api_send_buffer.append(payload)
#                 else:
#                     label_text = f"Fake Face ({confidence:.2f})"
#                     color = (0, 0, 255)

#                     # G·ª≠i full frame resized n·∫øu l√† fake (t·ªëi ƒëa m·ªói 5 gi√¢y)
#                     if not upload_queue.full() and (time.time() - last_fake_upload_time > 5):
#                         small_frame = cv2.resize(frame, (320, 240))
#                         upload_queue.put((small_frame.copy(), "unknown"))
#                         last_fake_upload_time = time.time()

#                 processed_results.append({'bbox': bbox, 'label': label_text, 'color': color})

#             results_queue.put(processed_results)
#             frames_queue.task_done()
#         except queue.Empty:
#             continue
#         except Exception as e:
#             print(f"‚ùå L·ªói trong lu·ªìng x·ª≠ l√Ω: {e}")

# # ====== Main Loop (Camera & Display) ======
# def main():
#     threading.Thread(target=processing_worker, daemon=True).start()
#     threading.Thread(target=uploader_worker, daemon=True).start()
#     threading.Thread(target=api_sender_worker, daemon=True).start()

#     print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")
#     cap = cv2.VideoCapture(0)
#     if not cap.isOpened():
#         print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
#         return

#     cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_RESOLUTION[0])
#     cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_RESOLUTION[1])

#     start_time = time.time()
#     frame_count = 0
#     static_results = []

#     while True:
#         ret, frame = cap.read()
#         if not ret:
#             break

#         if not frames_queue.full():
#             frames_queue.put(frame)

#         try:
#             new_results = results_queue.get_nowait()
#             static_results = new_results
#             results_queue.task_done()
#         except queue.Empty:
#             pass

#         for res in static_results:
#             bbox = res['bbox']
#             label = res['label']
#             color = res['color']
#             cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
#             cv2.putText(frame, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

#         frame_count += 1
#         elapsed_time = time.time() - start_time
#         fps = frame_count / elapsed_time
#         cv2.putText(frame, f"FPS: {fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

#         cv2.imshow("Realtime Recognition", frame)

#         if cv2.waitKey(1) & 0xFF == ord('q'):
#             break

#     cap.release()
#     cv2.destroyAllWindows()

# if __name__ == '__main__':
#     main()


# import time
# import cv2
# import numpy as np
# import faiss
# import pickle
# import os
# import warnings
# import requests
# import threading
# from datetime import datetime
# from insightface.app import FaceAnalysis
# from src.anti_spoof_predict import AntiSpoofPredict
# from src.generate_patches import CropImage
# from src.utility import parse_model_name

# warnings.filterwarnings('ignore')

# # ====== C·∫•u h√¨nh ======
# MODEL_DIR = "./resources/anti_spoof_models"
# MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
# DEVICE_ID = 0
# FAISS_PATH = "faiss_index/face_index.faiss"
# IDS_PATH = "faiss_index/student_ids.pkl"
# FAISS_THRESHOLD = 1.2
# API_URL = "http://localhost:5000/api/v1/exam-attendance/"

# # ====== Kh·ªüi t·∫°o m√¥ h√¨nh ch·ªëng gi·∫£ m·∫°o ======
# model_test = AntiSpoofPredict(DEVICE_ID)
# image_cropper = CropImage()
# h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

# # ====== Load FAISS index ======
# print("üìÇ ƒêang t·∫£i FAISS index v√† student_ids...")
# index = faiss.read_index(FAISS_PATH)
# with open(IDS_PATH, "rb") as f:
#     student_ids = pickle.load(f)
# print(f"‚úÖ ƒê√£ load FAISS index ({index.ntotal} vectors)")

# # ====== Kh·ªüi t·∫°o InsightFace ======
# app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
# app.prepare(ctx_id=0, det_size=(320, 320))

# # ====== G·ª≠i d·ªØ li·ªáu theo l√¥ ======
# send_buffer = []
# send_lock = threading.Lock()
# send_interval = 3  # gi√¢y

# def send_data_batch():
#     while True:
#         time.sleep(send_interval)
#         with send_lock:
#             buffer_copy = send_buffer.copy()
#             send_buffer.clear()

#         for record in buffer_copy:
#             try:
#                 response = requests.post(API_URL, json=record)
#                 if response.status_code in [200, 201]:
#                     print(f"‚úÖ G·ª≠i th√†nh c√¥ng: {record['name']} l√∫c {record['timestamp']}")
#                 else:
#                     print(f"‚ùå L·ªói g·ª≠i: {response.status_code} - {response.text}")
#             except Exception as e:
#                 print(f"‚ö†Ô∏è G·ª≠i l·ªói: {e}")

# # Kh·ªüi ƒë·ªông lu·ªìng g·ª≠i
# threading.Thread(target=send_data_batch, daemon=True).start()

# # ====== H√†m ch·ªëng gi·∫£ m·∫°o ======
# def is_real_face(frame, bbox):
#     image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
#     param = {
#         "org_img": frame,
#         "bbox": image_bbox,
#         "scale": scale,
#         "out_w": w_input,
#         "out_h": h_input,
#         "crop": True if scale is not None else False,
#     }
#     spoof_input = image_cropper.crop(**param)
#     prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
#     label = np.argmax(prediction)
#     confidence = prediction[0][label] / 2
#     return label == 1, confidence

# # ====== Nh·∫≠n di·ªán khu√¥n m·∫∑t ======
# def recognize_face(face_embedding):
#     embedding = face_embedding.astype(np.float32).reshape(1, -1)
#     embedding /= np.linalg.norm(embedding)
#     D, I = index.search(embedding, 1)
#     distance = float(D[0][0])
#     idx = int(I[0][0])
#     if distance < FAISS_THRESHOLD:
#         return student_ids[idx], distance
#     return "Unknown", distance

# # ====== V·∫Ω nh√£n l√™n khung h√¨nh ======
# def draw_label(frame, bbox, label_text, color):
#     cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
#     cv2.putText(frame, label_text, (bbox[0], bbox[1] - 10),
#                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# # ====== M·ªü webcam ======
# cap = cv2.VideoCapture(0)
# if not cap.isOpened():
#     print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
#     exit()

# print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")

# # ====== Bi·∫øn th·ªëng k√™ ======
# frame_count = 0
# face_count = 0
# total_elapsed_time = 0.0
# total_face_time = 0.0
# last_spoof_check = 0
# spoof_result = None

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         print("‚ö†Ô∏è L·ªói khi ƒë·ªçc webcam.")
#         break

#     frame_start_time = time.perf_counter()
#     faces = app.get(frame)
#     face_count += len(faces)

#     for face in faces:
#         bbox = face.bbox.astype(int)

#         # Anti-spoofing m·ªói 2 gi√¢y
#         if time.time() - last_spoof_check > 2:
#             is_real, confidence = is_real_face(frame, bbox)
#             spoof_result = (is_real, confidence)
#             last_spoof_check = time.time()

#         is_real, confidence = spoof_result if spoof_result else (False, 0.0)

#         face_start_time = time.perf_counter()

#         if is_real:
#             identity, dist = recognize_face(face.embedding)
#             label_text = f"{identity} ({dist:.2f})"
#             color = (0, 255, 0)

#             if identity != "Unknown":
#                 payload = {
#                     "name": identity,
#                     "confidence": round(dist, 2),
#                     "real_face": 1.0,
#                     "timestamp": datetime.now().isoformat()
#                 }
#                 with send_lock:
#                     send_buffer.append(payload)
#         else:
#             label_text = f"Fake Face ({confidence:.2f})"
#             color = (0, 0, 255)

#         draw_label(frame, bbox, label_text, color)

#         face_time = time.perf_counter() - face_start_time
#         total_face_time += face_time

#     # ƒê·∫øm khung h√¨nh
#     frame_count += 1
#     elapsed = time.perf_counter() - frame_start_time
#     total_elapsed_time += elapsed

#     fps = f"FPS: {1 / elapsed:.2f}"
#     cv2.putText(frame, fps, (10, 30),
#                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

#     cv2.imshow("Anti-Spoof + Face Recognition", frame)
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         break

# # ====== Gi·∫£i ph√≥ng ======
# cap.release()
# cv2.destroyAllWindows()

# # ====== Th·ªëng k√™ k·∫øt qu·∫£ ======
# print("\n===== TH·ªêNG K√ä HI·ªÜU SU·∫§T =====")
# print(f"T·ªïng s·ªë khung h√¨nh:        {frame_count}")
# print(f"T·ªïng s·ªë khu√¥n m·∫∑t:         {face_count}")
# print(f"Th·ªùi gian ch·∫°y (gi√¢y):     {total_elapsed_time:.2f}s")
# print(f"FPS trung b√¨nh:            {frame_count / total_elapsed_time:.2f}")
# print(f"Th·ªùi gian trung b√¨nh/face: {total_face_time / face_count:.4f} gi√¢y (n·∫øu c√≥ face)")

import time
import cv2
import numpy as np
import faiss
import pickle
import os
import warnings
import requests
import threading
import cloudinary
import cloudinary.uploader
import queue
from datetime import datetime
from insightface.app import FaceAnalysis
from src.anti_spoof_predict import AntiSpoofPredict
from src.generate_patches import CropImage
from src.utility import parse_model_name

warnings.filterwarnings('ignore')

# ====== Cloudinary config ======
cloudinary.config(
    cloud_name="dvc80qdie",
    api_key="221435714784277",
    api_secret="Zar2Kh6w0VBWp0rpQ5VYE-sbREI",
    secure=True
)

# ====== Config ======
MODEL_DIR = "./resources/anti_spoof_models"
MODEL_NAME = "2.7_80x80_MiniFASNetV2.pth"
DEVICE_ID = 0
FAISS_PATH = "faiss_index/face_index.faiss"
IDS_PATH = "faiss_index/student_ids.pkl"
FAISS_THRESHOLD = 1.2
API_URL = "http://localhost:5000/api/v1/exam-attendance/"


# ====== Init models ======
model_test = AntiSpoofPredict(DEVICE_ID)
image_cropper = CropImage()
h_input, w_input, model_type, scale = parse_model_name(MODEL_NAME)

print("üìÇ ƒêang t·∫£i FAISS index v√† student_ids...")
index = faiss.read_index(FAISS_PATH)
with open(IDS_PATH, "rb") as f:
    student_ids = pickle.load(f)
print(f"‚úÖ ƒê√£ load FAISS index ({index.ntotal} vectors)")

app = FaceAnalysis(name='buffalo_sc', providers=['CPUExecutionProvider'])
app.prepare(ctx_id=0, det_size=(320, 320))

# ====== Send batch thread ======
send_buffer = []
send_lock = threading.Lock()
send_interval = 3

def send_data_batch():
    while True:
        time.sleep(send_interval)
        with send_lock:
            buffer_copy = send_buffer.copy()
            send_buffer.clear()

        for record in buffer_copy:
            try:
                response = requests.post(API_URL, json=record)
                if response.status_code in [200, 201]:
                    print(f"‚úÖ G·ª≠i th√†nh c√¥ng: {record['name']} l√∫c {record['timestamp']}")
                else:
                    print(f"‚ùå L·ªói g·ª≠i: {response.status_code} - {response.text}")
            except Exception as e:
                print(f"‚ö†Ô∏è G·ª≠i l·ªói: {e}")

threading.Thread(target=send_data_batch, daemon=True).start()

# ====== Upload fake face to Cloudinary ======
# def upload_fake_face_to_cloudinary(frame, bbox):
#     x1, y1, x2, y2 = bbox
#     cropped_face = frame[y1:y2, x1:x2]
#     _, img_encoded = cv2.imencode('.jpg', cropped_face)
#     response = cloudinary.uploader.upload(
#         img_encoded.tobytes(),
#         folder="fake_faces",
#         public_id=f"fakeface_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
#         resource_type="image"
#     )
#     print(f"‚òÅÔ∏è Fake face ƒë√£ upload: {response.get('secure_url')}")
#     return response.get("secure_url")

def upload_fake_face_to_cloudinary(frame, bbox):
    # G·ª≠i to√†n b·ªô khung h√¨nh (frame), kh√¥ng crop
    _, img_encoded = cv2.imencode('.jpg', frame)

    response = cloudinary.uploader.upload(
        img_encoded.tobytes(),
        folder="fake_faces_fullframe",
        public_id=f"fakeframe_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        resource_type="image"
    )
    print(f"‚òÅÔ∏è ·∫¢nh to√†n khung ch·ª©a fake face ƒë√£ upload: {response.get('secure_url')}")
    return response.get("secure_url")


# ====== Fake face queue + thread ======
fake_face_queue = queue.Queue()

def fake_face_uploader():
    while True:
        frame, bbox = fake_face_queue.get()
        if frame is None:
            break
        try:
            upload_fake_face_to_cloudinary(frame, bbox)
        except Exception as e:
            print("‚ùå L·ªói khi upload ·∫£nh fake:", e)

threading.Thread(target=fake_face_uploader, daemon=True).start()

# ====== Anti-spoofing ======
def is_real_face(frame, bbox):
    image_bbox = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
    param = {
        "org_img": frame,
        "bbox": image_bbox,
        "scale": scale,
        "out_w": w_input,
        "out_h": h_input,
        "crop": True if scale is not None else False,
    }
    spoof_input = image_cropper.crop(**param)
    prediction = model_test.predict(spoof_input, os.path.join(MODEL_DIR, MODEL_NAME))
    label = np.argmax(prediction)
    confidence = prediction[0][label] / 2
    return label == 1, confidence

# ====== Face recognition ======
def recognize_face(face_embedding):
    embedding = face_embedding.astype(np.float32).reshape(1, -1)
    embedding /= np.linalg.norm(embedding)
    D, I = index.search(embedding, 1)
    distance = float(D[0][0])
    idx = int(I[0][0])
    if distance < FAISS_THRESHOLD:
        
        return student_ids[idx], distance
    return "Unknown", distance

# ====== Draw label ======
def draw_label(frame, bbox, label_text, color):
    cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
    cv2.putText(frame, label_text, (bbox[0], bbox[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# ====== Camera ======
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.")
    exit()

print("üì∑ Nh·∫≠n di·ªán realtime (·∫•n 'q' ƒë·ªÉ tho√°t)")

frame_count = 0
face_count = 0
total_elapsed_time = 0.0
total_face_time = 0.0
last_spoof_check = 0
spoof_result = None

last_fake_upload_time = 0
fake_upload_interval = 10  # gi√¢y, kho·∫£ng c√°ch gi·ªØa c√°c l·∫ßn g·ª≠i fake face

while True:
    ret, frame = cap.read()
    if not ret:
        print("‚ö†Ô∏è L·ªói khi ƒë·ªçc webcam.")
        break

    frame_start_time = time.perf_counter()
    faces = app.get(frame)
    face_count += len(faces)

    for face in faces:
        bbox = face.bbox.astype(int)

        if time.time() - last_spoof_check > 2:
            is_real, confidence = is_real_face(frame, bbox)
            spoof_result = (is_real, confidence)
            last_spoof_check = time.time()

        is_real, confidence = spoof_result if spoof_result else (False, 0.0)

        face_start_time = time.perf_counter()

        if is_real:
            identity, dist = recognize_face(face.embedding)
            label_text = f"{identity} ({dist:.2f})"
            color = (0, 255, 0)

            if identity != "Unknown":
                payload = {
                    "name": identity,
                    "confidence": round(dist, 2),
                    "real_face": 1.0,
                    "timestamp": datetime.now().isoformat()
                }
                with send_lock:
                    send_buffer.append(payload)
        else:
            label_text = f"Fake Face ({confidence:.2f})"
            color = (0, 0, 255)

            # üßµ G·ª≠i ·∫£nh fake v√†o queue x·ª≠ l√Ω upload ri√™ng
            # fake_face_queue.put((frame.copy(), bbox))
            current_time = time.time()
            if current_time - last_fake_upload_time > fake_upload_interval:
                fake_face_queue.put((frame.copy(), bbox))
                last_fake_upload_time = current_time

        draw_label(frame, bbox, label_text, color)

        face_time = time.perf_counter() - face_start_time
        total_face_time += face_time

    frame_count += 1
    elapsed = time.perf_counter() - frame_start_time
    total_elapsed_time += elapsed

    fps = f"FPS: {1 / elapsed:.2f}"
    cv2.putText(frame, fps, (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

    cv2.imshow("Anti-Spoof + Face Recognition", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ====== Cleanup ======
cap.release()
cv2.destroyAllWindows()
fake_face_queue.put((None, None))  # k·∫øt th√∫c thread upload n·∫øu c·∫ßn

# ====== Stats ======
print("\n===== TH·ªêNG K√ä HI·ªÜU SU·∫§T =====")
print(f"T·ªïng s·ªë khung h√¨nh:        {frame_count}")
print(f"T·ªïng s·ªë khu√¥n m·∫∑t:         {face_count}")
print(f"Th·ªùi gian ch·∫°y (gi√¢y):     {total_elapsed_time:.2f}s")
print(f"FPS trung b√¨nh:            {frame_count / total_elapsed_time:.2f}")
if face_count > 0:
    print(f"Th·ªùi gian trung b√¨nh/face: {total_face_time / face_count:.4f} gi√¢y")
